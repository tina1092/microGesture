{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4df6729-c793-4761-8485-67affed98f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 22:37:37.069355: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 22:37:37.073545: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-11 22:37:37.087172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-11 22:37:37.109887: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-11 22:37:37.116536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-11 22:37:37.132637: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 22:37:38.196714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "SerialException",
     "evalue": "[Errno 2] could not open port /dev/tty.usbmodem144050001: [Errno 2] No such file or directory: '/dev/tty.usbmodem144050001'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/serial/serialposix.py:322\u001b[0m, in \u001b[0;36mSerial.open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mportstr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mO_RDWR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mO_NOCTTY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mO_NONBLOCK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m msg:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dev/tty.usbmodem144050001'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# import matplotlib as mpl\u001b[39;00m\n\u001b[1;32m     14\u001b[0m port \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/dev/tty.usbmodem144050001\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#131357501\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m ser \u001b[38;5;241m=\u001b[39m \u001b[43mserial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m115200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/serial/serialutil.py:244\u001b[0m, in \u001b[0;36mSerialBase.__init__\u001b[0;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munexpected keyword arguments: \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(kwargs))\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m port \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/serial/serialposix.py:325\u001b[0m, in \u001b[0;36mSerial.open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m msg:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerialException(msg\u001b[38;5;241m.\u001b[39merrno, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not open port \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port, msg))\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m#~ fcntl.fcntl(self.fd, fcntl.F_SETFL, 0)  # set blocking\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe_abort_read_r, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe_abort_read_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mSerialException\u001b[0m: [Errno 2] could not open port /dev/tty.usbmodem144050001: [Errno 2] No such file or directory: '/dev/tty.usbmodem144050001'"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import Counter\n",
    "\n",
    "# import matplotlib as mpl\n",
    "\n",
    "\n",
    "port = '/dev/tty.usbmodem144050001' #131357501\n",
    "ser = serial.Serial(port, 115200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f7815",
   "metadata": {},
   "source": [
    "# microGesture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f395267f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 215\u001b[0m\n\u001b[1;32m    212\u001b[0m force_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    213\u001b[0m result_map \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mips\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmpr\u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 215\u001b[0m y_pred, y_test, x_test_list, x_test_list_preNormalize \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_txt_and_predict_force\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_file_path_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresult_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m, in \u001b[0;36manalyze_txt_and_predict_force\u001b[0;34m(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_txt_and_predict_force\u001b[39m(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame_interval \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m window_size:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manalyze_txt_and_predict_force_overlap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_file_path_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m analyze_txt_and_predict_force_nonOverlap(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36manalyze_txt_and_predict_force_overlap\u001b[0;34m(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\u001b[0m\n\u001b[1;32m     10\u001b[0m     normalized_data \u001b[38;5;241m=\u001b[39m (raw_data \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalized_data\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(model_file_path)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Temporary lists to hold data before packing into the main lists (as a queue)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m temp_real_queue \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_txt_and_predict_force(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n",
    "    if frame_interval <= window_size:\n",
    "        return analyze_txt_and_predict_force_overlap(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\n",
    "    else:\n",
    "        return analyze_txt_and_predict_force_nonOverlap(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\n",
    "def analyze_txt_and_predict_force_overlap(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n",
    "    def normalize(raw_data):\n",
    "        mean = np.mean(raw_data, axis=0)\n",
    "        std = np.std(raw_data, axis=0)\n",
    "        normalized_data = (raw_data - mean) / std\n",
    "        return normalized_data\n",
    "    \n",
    "    model = load_model(model_file_path)\n",
    "\n",
    "    # Temporary lists to hold data before packing into the main lists (as a queue)\n",
    "    temp_real_queue = []\n",
    "    temp_imaginary_queue = []\n",
    "    temp_force_queue = []\n",
    "    temp_gesture_queue = []\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    x_test_list = []\n",
    "    x_test_list_preNormalize = []\n",
    "    if not os.path.exists(write_file_path_root):\n",
    "        os.makedirs(write_file_path_root)\n",
    "    write_file_path = os.path.join(write_file_path_root, write_file_name)\n",
    "    with open(write_file_path, 'w') as f:\n",
    "        frame_count = 0  # To track the total number of frames processed\n",
    "        extracting_frames = False  # Flag to indicate if we are in an extraction block\n",
    "        lines_in_frame = 0  # To count lines within a frame block\n",
    "        predict_size = 0\n",
    "        while True:\n",
    "        # with open(read_file_path, 'r') as file:\n",
    "            # for line in file:\n",
    "                line = ser.readline().decode()\n",
    "                line = line.strip()\n",
    "                line_part = line.split()\n",
    "                # Detect the start of a new frame\n",
    "                if line_part[0] == \"frame\":\n",
    "                    frame_count += 1\n",
    "                    lines_in_frame = 0  # Reset line count for the new frame\n",
    "                    extracting_frames = True  # Always extracting frames\n",
    "\n",
    "                # If we're extracting frames, process the next 3 lines\n",
    "                if extracting_frames:\n",
    "                    temp_gesture_queue.append(line_part[1])\n",
    "                    if lines_in_frame == 1:  # First data line (real values)\n",
    "                        temp_real_queue.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 2:  # Second data line (imaginary values)\n",
    "                        temp_imaginary_queue.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 3:  # Third data line (force values)\n",
    "                        force_value = float(line.split()[0])  # Extract the first value (force)\n",
    "                        temp_force_queue.append(force_value)\n",
    "\n",
    "                        # If the queue length reaches frames_to_extract, perform prediction\n",
    "                        if len(temp_real_queue) == window_size:\n",
    "                            # Convert queue data to numpy arrays\n",
    "                            np_real_list = np.array(temp_real_queue)\n",
    "                            np_imaginary_list = np.array(temp_imaginary_queue)\n",
    "                            np_force_list = np.array(temp_force_queue)\n",
    "                            np_force_mean_value = np.mean(np_force_list)\n",
    "\n",
    "                            gesture_word_counts = Counter(temp_gesture_queue)\n",
    "                            y_test_value = gesture_word_counts.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "                            if np_force_mean_value < force_threshold:\n",
    "                                np_force_mean_value = 0\n",
    "                            # Combine real and imaginary parts\n",
    "                            combined_12 = np.concatenate((np_real_list, np_imaginary_list), axis=1)\n",
    "                            x_test_list_preNormalize.append(combined_12)\n",
    "                            # combined_12 = normalize(combined_12)\n",
    "                            x_test_list.append(combined_12)\n",
    "                            X_test = np.expand_dims(combined_12, axis=0)\n",
    "                            # Perform prediction\n",
    "                            y_pred_value = model.predict(X_test)\n",
    "                            y_pred_labels = np.argmax(y_pred_value, axis=1)\n",
    "                            predict_size += 1\n",
    "                            y_pred.append(result_map[y_pred_labels[0]])\n",
    "                            y_test.append(np_force_mean_value)\n",
    "                            # Write results to file\n",
    "                            f.write(f\"Predict {predict_size}: \\n\")\n",
    "                            f.write(f\"force mean: {np_force_mean_value}\\n\")\n",
    "                            f.write(f\"ground truth frame type: {y_test_value}\\n\")\n",
    "                            f.write(f\"predict frame type: {result_map[y_pred_labels[0]]}\\n\")\n",
    "\n",
    "                            # Remove the oldest frame to allow overlap\n",
    "                            for delete in range(frame_interval):\n",
    "                                temp_real_queue.pop(0)\n",
    "                                temp_imaginary_queue.pop(0)\n",
    "                                temp_force_queue.pop(0)\n",
    "\n",
    "                # Count lines within a frame block\n",
    "                if extracting_frames:\n",
    "                    lines_in_frame += 1\n",
    "        ser.close()\n",
    "    f.close()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred_write_file_path = os.path.join(write_file_path_root, \"y_pred\")\n",
    "    np.save(y_pred_write_file_path, y_pred)\n",
    "    y_test_write_file_path = os.path.join(write_file_path_root, \"y_test\")\n",
    "    np.save(y_test_write_file_path, y_test)\n",
    "    return y_pred, y_test, np.array(x_test_list), np.array(x_test_list_preNormalize)\n",
    "\n",
    "def analyze_txt_and_predict_force_nonOverlap(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n",
    "    def normalize(raw_data):\n",
    "        mean = np.mean(raw_data, axis=0)\n",
    "        std = np.std(raw_data, axis=0)\n",
    "        normalized_data = (raw_data - mean) / std\n",
    "        return normalized_data\n",
    "    model = load_model(model_file_path)\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    x_test_list = []\n",
    "    x_test_list_preNormalize = []\n",
    "    if not os.path.exists(write_file_path_root):\n",
    "        os.makedirs(write_file_path_root)\n",
    "    write_file_path = os.path.join(write_file_path_root, write_file_name)\n",
    "    with open(write_file_path, 'w') as f:\n",
    "        frame_count = 0  # To track the total number of frames processed\n",
    "        extracting_frames = False  # Flag to indicate if we are in an extraction block\n",
    "        lines_in_frame = 0  # To count lines within a frame block\n",
    "        predict_size = 0\n",
    "        while True:\n",
    "        # with open(read_file_path, 'r') as file:\n",
    "            # for line in file:\n",
    "                line = ser.readline().decode()\n",
    "                line = line.strip()\n",
    "                line_part = line.split()\n",
    "                # Detect the start of a new frame\n",
    "                if line_part[0] == \"frame\":\n",
    "                    frame_count += 1\n",
    "                    lines_in_frame = 0  # Reset line count for the new frame\n",
    "\n",
    "                    # Check if it's time to start extracting frames\n",
    "                    if frame_count % frame_interval == 0:\n",
    "                        extracting_frames = True\n",
    "                        frames_extracted = 0  # Reset the number of extracted frames for this block\n",
    "                        temp_real_list = []  # Clear temp lists for this extraction block\n",
    "                        temp_imaginary_list = []\n",
    "                        temp_force_list = []\n",
    "                        temp_gesture_list = []\n",
    "\n",
    "                # If we're extracting frames, process the next 3 lines\n",
    "                if extracting_frames:\n",
    "                    temp_gesture_list.append(line_part[1])\n",
    "                    if lines_in_frame == 1:  # First data line (real values)\n",
    "                        temp_real_list.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 2:  # Second data line (imaginary values)\n",
    "                        temp_imaginary_list.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 3:  # Third data line (force values)\n",
    "                        force_value = float(line.split()[0])  # Extract the first value (force)\n",
    "                        temp_force_list.append(force_value)\n",
    "                        frames_extracted += 1  # Increment frames extracted count\n",
    "\n",
    "\n",
    "                        # If we have extracted enough frames (frames_to_extract), store them\n",
    "                        if frames_extracted == window_size:\n",
    "                            # Convert queue data to numpy arrays\n",
    "                            np_real_list = np.array(temp_real_list)\n",
    "                            np_imaginary_list = np.array(temp_imaginary_list)\n",
    "                            np_force_list = np.array(temp_force_list)\n",
    "                            np_force_mean_value = np.mean(np_force_list)\n",
    "\n",
    "                            gesture_word_counts = Counter(temp_gesture_list)\n",
    "                            y_test_value = gesture_word_counts.most_common(1)[0][0]\n",
    "\n",
    "                            if np_force_mean_value < force_threshold:\n",
    "                                np_force_mean_value = 0\n",
    "                            # Combine real and imaginary parts\n",
    "                            combined_12 = np.concatenate((np_real_list, np_imaginary_list), axis=1)\n",
    "                            x_test_list_preNormalize.append(combined_12)\n",
    "                            # combined_12 = normalize(combined_12)\n",
    "                            x_test_list.append(combined_12)\n",
    "                            X_test = np.expand_dims(combined_12, axis=0)\n",
    "                            # Perform prediction\n",
    "                            y_pred_value = model.predict(X_test)\n",
    "                            y_pred_labels = np.argmax(y_pred_value, axis=1)\n",
    "                            predict_size += 1\n",
    "\n",
    "                            y_pred.append(result_map[y_pred_labels[0]])\n",
    "                            y_test.append(np_force_mean_value)\n",
    "                            # Write results to file\n",
    "                            f.write(f\"Predict {predict_size}: \\n\")\n",
    "                            f.write(f\"force mean: {np_force_mean_value}\\n\")\n",
    "                            f.write(f\"ground truth frame type: {y_test_value}\\n\")\n",
    "                            f.write(f\"predict frame type: {result_map[y_pred_labels[0]]}\\n\")\n",
    "\n",
    "                            extracting_frames = False  # Stop extracting for this interval\n",
    "\n",
    "                # Count lines within a frame block\n",
    "                if extracting_frames:\n",
    "                    lines_in_frame += 1\n",
    "        ser.close()\n",
    "    f.close()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred_write_file_path = os.path.join(write_file_path_root, \"y_pred\")\n",
    "    np.save(y_pred_write_file_path, y_pred)\n",
    "    y_test_write_file_path = os.path.join(write_file_path_root, \"y_test\")\n",
    "    np.save(y_test_write_file_path, y_test)\n",
    "    return y_pred, y_test, np.array(x_test_list), np.array(x_test_list_preNormalize)\n",
    "\n",
    "model_file_path = \"/home/ubuntu/paper_arm_model/best_model/best_gesture_model.h5\"\n",
    "write_file_name = \"microGesture_predict_result_and_ground_truth.txt\"\n",
    "write_file_path_root = \"/home/ubuntu/paper_arm_model/best_model_result/test2\"\n",
    "frame_interval = 2  # Number of frames to skip between extractions\n",
    "window_size = 60  # Number of frames to extract after the interval\n",
    "force_threshold = 0.5\n",
    "result_map = ['id', 'ipr', 'ips', 'mpr' ,'mps', 'sl', 'sr']\n",
    "\n",
    "y_pred, y_test, x_test_list, x_test_list_preNormalize = analyze_txt_and_predict_force(model_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold,result_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbafa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

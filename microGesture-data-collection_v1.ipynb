{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4df6729-c793-4761-8485-67affed98f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 00:31:43.007766: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-24 00:31:43.408287: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-24 00:31:43.838267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 00:31:44.155195: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 00:31:44.239953: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 00:31:44.897137: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 00:31:47.354758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from collections import Counter\n",
    "\n",
    "# import matplotlib as mpl\n",
    "\n",
    "\n",
    "# port = '/dev/tty.usbmodem144050001' #131357501\n",
    "# ser = serial.Serial(port, 115200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17f7815",
   "metadata": {},
   "source": [
    "# microGesture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34fcc241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "def analyze_txt_and_predict_force(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n",
    "    if frame_interval <= window_size:\n",
    "        return analyze_txt_and_predict_force_overlap(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\n",
    "    else:\n",
    "        return analyze_txt_and_predict_force_nonOverlap(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map)\n",
    "def analyze_txt_and_predict_force_overlap(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n",
    "    def normalize(raw_data):\n",
    "        mean = np.mean(raw_data, axis=0)\n",
    "        std = np.std(raw_data, axis=0)\n",
    "        normalized_data = (raw_data - mean) / std\n",
    "        return normalized_data\n",
    "    \n",
    "    model = load_model(model_file_path)\n",
    "\n",
    "    # Temporary lists to hold data before packing into the main lists (as a queue)\n",
    "    temp_real_queue = []\n",
    "    temp_imaginary_queue = []\n",
    "    temp_force_queue = []\n",
    "    temp_gesture_queue = []\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    x_test_list = []\n",
    "    x_test_list_preNormalize = []\n",
    "    if not os.path.exists(write_file_path_root):\n",
    "        os.makedirs(write_file_path_root)\n",
    "    write_file_path = os.path.join(write_file_path_root, write_file_name)\n",
    "    with open(write_file_path, 'w') as f:\n",
    "        frame_count = 0  # To track the total number of frames processed\n",
    "        extracting_frames = False  # Flag to indicate if we are in an extraction block\n",
    "        lines_in_frame = 0  # To count lines within a frame block\n",
    "        predict_size = 0\n",
    "        # while True:\n",
    "        with open(read_file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # line = ser.readline().decode()\n",
    "                line = line.strip()\n",
    "                line_part = line.split()\n",
    "                # Detect the start of a new frame\n",
    "                if line_part[0] == \"frame\":\n",
    "                    frame_count += 1\n",
    "                    lines_in_frame = 0  # Reset line count for the new frame\n",
    "                    extracting_frames = True  # Always extracting frames\n",
    "\n",
    "                # If we're extracting frames, process the next 3 lines\n",
    "                if extracting_frames:\n",
    "                    temp_gesture_queue.append(line_part[1])\n",
    "                    if lines_in_frame == 1:  # First data line (real values)\n",
    "                        temp_real_queue.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 2:  # Second data line (imaginary values)\n",
    "                        temp_imaginary_queue.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 3:  # Third data line (force values)\n",
    "                        force_value = float(line.split()[0])  # Extract the first value (force)\n",
    "                        temp_force_queue.append(force_value)\n",
    "\n",
    "                        # If the queue length reaches frames_to_extract, perform prediction\n",
    "                        if len(temp_real_queue) == window_size:\n",
    "                            # Convert queue data to numpy arrays\n",
    "                            np_real_list = np.array(temp_real_queue)\n",
    "                            np_imaginary_list = np.array(temp_imaginary_queue)\n",
    "                            np_force_list = np.array(temp_force_queue)\n",
    "                            np_force_mean_value = np.mean(np_force_list)\n",
    "\n",
    "                            gesture_word_counts = Counter(temp_gesture_queue)\n",
    "                            y_test_value = gesture_word_counts.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "                            if np_force_mean_value < force_threshold:\n",
    "                                np_force_mean_value = 0\n",
    "                            # Combine real and imaginary parts\n",
    "                            combined_12 = np.concatenate((np_real_list, np_imaginary_list), axis=1)\n",
    "                            x_test_list_preNormalize.append(combined_12)\n",
    "                            # combined_12 = normalize(combined_12)\n",
    "                            x_test_list.append(combined_12)\n",
    "                            X_test = np.expand_dims(combined_12, axis=0)\n",
    "                            # Perform prediction\n",
    "                            y_pred_value = model.predict(X_test, verbose=0)\n",
    "                            y_pred_labels = np.argmax(y_pred_value, axis=1)\n",
    "                            predict_size += 1\n",
    "                            y_pred.append(result_map[y_pred_labels[0]])\n",
    "                            y_test.append(np_force_mean_value)\n",
    "                            print(result_map[y_pred_labels[0]])\n",
    "                            # Write results to file\n",
    "                            f.write(f\"Predict {predict_size}: \\n\")\n",
    "                            f.write(f\"force mean: {np_force_mean_value}\\n\")\n",
    "                            f.write(f\"ground truth frame type: {y_test_value}\\n\")\n",
    "                            f.write(f\"predict frame type: {result_map[y_pred_labels[0]]}\\n\")\n",
    "\n",
    "                            # Remove the oldest frame to allow overlap\n",
    "                            for delete in range(frame_interval):\n",
    "                                temp_real_queue.pop(0)\n",
    "                                temp_imaginary_queue.pop(0)\n",
    "                                temp_force_queue.pop(0)\n",
    "\n",
    "                # Count lines within a frame block\n",
    "                if extracting_frames:\n",
    "                    lines_in_frame += 1\n",
    "        # ser.close()\n",
    "    f.close()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred_write_file_path = os.path.join(write_file_path_root, \"y_pred\")\n",
    "    np.save(y_pred_write_file_path, y_pred)\n",
    "    y_test_write_file_path = os.path.join(write_file_path_root, \"y_test\")\n",
    "    np.save(y_test_write_file_path, y_test)\n",
    "    return y_pred, y_test, np.array(x_test_list), np.array(x_test_list_preNormalize)\n",
    "\n",
    "def analyze_txt_and_predict_force_nonOverlap(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold, result_map):\n",
    "    def normalize(raw_data):\n",
    "        mean = np.mean(raw_data, axis=0)\n",
    "        std = np.std(raw_data, axis=0)\n",
    "        normalized_data = (raw_data - mean) / std\n",
    "        return normalized_data\n",
    "    model = load_model(model_file_path)\n",
    "\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    x_test_list = []\n",
    "    x_test_list_preNormalize = []\n",
    "    if not os.path.exists(write_file_path_root):\n",
    "        os.makedirs(write_file_path_root)\n",
    "    write_file_path = os.path.join(write_file_path_root, write_file_name)\n",
    "    with open(write_file_path, 'w') as f:\n",
    "        frame_count = 0  # To track the total number of frames processed\n",
    "        extracting_frames = False  # Flag to indicate if we are in an extraction block\n",
    "        lines_in_frame = 0  # To count lines within a frame block\n",
    "        predict_size = 0\n",
    "        # while True:\n",
    "        with open(read_file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # line = ser.readline().decode()\n",
    "                line = line.strip()\n",
    "                line_part = line.split()\n",
    "                # Detect the start of a new frame\n",
    "                if line_part[0] == \"frame\":\n",
    "                    frame_count += 1\n",
    "                    lines_in_frame = 0  # Reset line count for the new frame\n",
    "\n",
    "                    # Check if it's time to start extracting frames\n",
    "                    if frame_count % frame_interval == 0:\n",
    "                        extracting_frames = True\n",
    "                        frames_extracted = 0  # Reset the number of extracted frames for this block\n",
    "                        temp_real_list = []  # Clear temp lists for this extraction block\n",
    "                        temp_imaginary_list = []\n",
    "                        temp_force_list = []\n",
    "                        temp_gesture_list = []\n",
    "\n",
    "                # If we're extracting frames, process the next 3 lines\n",
    "                if extracting_frames:\n",
    "                    temp_gesture_list.append(line_part[1])\n",
    "                    if lines_in_frame == 1:  # First data line (real values)\n",
    "                        temp_real_list.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 2:  # Second data line (imaginary values)\n",
    "                        temp_imaginary_list.append([float(num) for num in line.split()])\n",
    "                    elif lines_in_frame == 3:  # Third data line (force values)\n",
    "                        force_value = float(line.split()[0])  # Extract the first value (force)\n",
    "                        temp_force_list.append(force_value)\n",
    "                        frames_extracted += 1  # Increment frames extracted count\n",
    "\n",
    "\n",
    "                        # If we have extracted enough frames (frames_to_extract), store them\n",
    "                        if frames_extracted == window_size:\n",
    "                            # Convert queue data to numpy arrays\n",
    "                            np_real_list = np.array(temp_real_list)\n",
    "                            np_imaginary_list = np.array(temp_imaginary_list)\n",
    "                            np_force_list = np.array(temp_force_list)\n",
    "                            np_force_mean_value = np.mean(np_force_list)\n",
    "\n",
    "                            gesture_word_counts = Counter(temp_gesture_list)\n",
    "                            y_test_value = gesture_word_counts.most_common(1)[0][0]\n",
    "\n",
    "                            if np_force_mean_value < force_threshold:\n",
    "                                np_force_mean_value = 0\n",
    "                            # Combine real and imaginary parts\n",
    "                            combined_12 = np.concatenate((np_real_list, np_imaginary_list), axis=1)\n",
    "                            x_test_list_preNormalize.append(combined_12)\n",
    "                            # combined_12 = normalize(combined_12)\n",
    "                            x_test_list.append(combined_12)\n",
    "                            X_test = np.expand_dims(combined_12, axis=0)\n",
    "                            # Perform prediction\n",
    "                            y_pred_value = model.predict(X_test, verbose=0)\n",
    "                            y_pred_labels = np.argmax(y_pred_value, axis=1)\n",
    "                            predict_size += 1\n",
    "\n",
    "                            y_pred.append(result_map[y_pred_labels[0]])\n",
    "                            y_test.append(np_force_mean_value)\n",
    "                            # Write results to file\n",
    "                            f.write(f\"Predict {predict_size}: \\n\")\n",
    "                            f.write(f\"force mean: {np_force_mean_value}\\n\")\n",
    "                            f.write(f\"ground truth frame type: {y_test_value}\\n\")\n",
    "                            f.write(f\"predict frame type: {result_map[y_pred_labels[0]]}\\n\")\n",
    "\n",
    "                            extracting_frames = False  # Stop extracting for this interval\n",
    "\n",
    "                # Count lines within a frame block\n",
    "                if extracting_frames:\n",
    "                    lines_in_frame += 1\n",
    "        # ser.close()\n",
    "    f.close()\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_test = np.array(y_test)\n",
    "    y_pred_write_file_path = os.path.join(write_file_path_root, \"y_pred\")\n",
    "    np.save(y_pred_write_file_path, y_pred)\n",
    "    y_test_write_file_path = os.path.join(write_file_path_root, \"y_test\")\n",
    "    np.save(y_test_write_file_path, y_test)\n",
    "    return y_pred, y_test, np.array(x_test_list), np.array(x_test_list_preNormalize)\n",
    "\n",
    "\n",
    "model_file_path = \"/home/ubuntu/paper_arm_model/best_model/best_gesture_model.h5\"\n",
    "read_file_path = \"/home/ubuntu/paper_arm_model/EIT_Model_Input_Resource/original_resource/p1-50kHz-1mA-6m-MG_1.txt\"\n",
    "write_file_name = \"microGesture_predict_result_and_ground_truth.txt\"\n",
    "write_file_path_root = \"/home/ubuntu/paper_arm_model/best_model_result/test2\"\n",
    "frame_interval = 100 # Number of frames to skip between extractions\n",
    "window_size = 60  # Number of frames to extract after the interval\n",
    "force_threshold = 0.5\n",
    "result_map = ['id', 'ipr', 'ips', 'mpr' ,'mps', 'sl', 'sr']\n",
    "\n",
    "y_pred, y_test, x_test_list, x_test_list_preNormalize = analyze_txt_and_predict_force(model_file_path, read_file_path, write_file_name, write_file_path_root, frame_interval, window_size, force_threshold,result_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73aca614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mps', 'ipr', 'id', 'id', 'ips', 'id', 'ips', 'id', 'ipr', 'ips',\n",
       "       'ipr', 'id', 'ipr', 'ips', 'ipr', 'ips', 'ipr', 'ips', 'ipr', 'id',\n",
       "       'ips', 'id', 'ips', 'id', 'ips', 'id', 'ipr', 'ips', 'ipr', 'ips',\n",
       "       'ipr', 'ips', 'ipr', 'ips', 'ipr', 'ips', 'ipr', 'ips', 'ipr',\n",
       "       'id', 'ipr', 'id', 'ipr', 'id', 'ipr', 'id', 'ipr', 'id', 'ips',\n",
       "       'id', 'ips', 'id', 'ips', 'id', 'ipr', 'ips', 'id', 'ips', 'id',\n",
       "       'ips', 'id', 'ips', 'sl', 'ips', 'sl', 'ips', 'sl', 'ipr', 'sl',\n",
       "       'ipr', 'sl', 'ipr', 'sl', 'id', 'mps', 'sl', 'mps', 'sl', 'mps',\n",
       "       'sl', 'mps', 'sl', 'mps', 'sl', 'mps', 'mpr', 'mps', 'mpr', 'mps',\n",
       "       'mpr', 'mps', 'mpr', 'mps', 'mpr', 'mps', 'mpr', 'mps', 'mpr',\n",
       "       'mps', 'mpr', 'mps', 'mpr', 'mps', 'sl', 'mps', 'mpr', 'mps',\n",
       "       'mpr', 'mps', 'mpr', 'sl', 'sl', 'sl', 'sl', 'sl', 'mps', 'sl',\n",
       "       'mps', 'sl', 'mps', 'id', 'mps', 'mpr', 'mps', 'mpr', 'mps', 'mpr',\n",
       "       'sl', 'sl', 'mps', 'sl', 'mps', 'sl', 'mps', 'sl', 'mps', 'mpr',\n",
       "       'mps', 'sl', 'sl', 'sl', 'sl', 'sl', 'sl', 'mps', 'sl', 'sr', 'sl',\n",
       "       'sl', 'sr', 'sl', 'sr', 'sl', 'id', 'sl', 'sr', 'sl', 'sl', 'sl',\n",
       "       'sl', 'sr', 'sl', 'sr', 'sl', 'sr', 'sl', 'id', 'sl', 'mps', 'sl',\n",
       "       'sl', 'sl', 'sr', 'sl', 'id', 'sl', 'mps', 'sl', 'sl', 'sl', 'sl',\n",
       "       'sl', 'sl', 'mps', 'sl', 'sl', 'sl', 'sr', 'sl', 'sr', 'sl', 'sr',\n",
       "       'sl', 'id', 'sl', 'sl', 'sl', 'id', 'sl', 'id', 'sl', 'sl', 'sl',\n",
       "       'mps', 'sl', 'sl', 'sl', 'sl', 'sl', 'sl', 'id', 'sl', 'sl', 'id',\n",
       "       'sl', 'sl', 'sl', 'mpr', 'sl', 'sl', 'sl', 'mpr', 'sl', 'mpr',\n",
       "       'sl', 'sl', 'id', 'sr', 'sl', 'id', 'sl', 'sr', 'id', 'sr', 'sl',\n",
       "       'mps', 'id', 'id', 'sl', 'id', 'id', 'id', 'id', 'id', 'sl', 'sl',\n",
       "       'sl', 'id', 'sl', 'id', 'sl', 'sl', 'sl', 'sl', 'mps', 'id', 'id',\n",
       "       'id', 'id', 'sl', 'id', 'id', 'id', 'id', 'id', 'sl', 'id', 'sl',\n",
       "       'id', 'id', 'id', 'id', 'id', 'sl', 'sl', 'sl', 'id', 'mps', 'id',\n",
       "       'mps', 'id', 'ips', 'id', 'sr', 'id', 'id', 'id', 'sl', 'sl', 'id',\n",
       "       'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id',\n",
       "       'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id', 'id'],\n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d740c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
